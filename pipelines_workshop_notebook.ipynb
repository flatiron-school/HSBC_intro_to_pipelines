{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Pipelines in Python\n",
    "\n",
    "## Objectives\n",
    "- Understand what a pipeline is and why they are used\n",
    "- Implement a pipeline to streamline the preprocessing and modeling workflow\n",
    "\n",
    "## Why Pipeline?\n",
    "\n",
    "A pipeline defines a series of sequential steps or processes that data must \"flow\" through. Pipelines can keep our code neat and clean all the way from gathering & cleaning our data, to creating models & fine-tuning them!\n",
    "\n",
    "**Advantages**: \n",
    "- Reduces complexity\n",
    "- Convenient \n",
    "- Flexible \n",
    "- Can help prevent mistakes (like data leakage between train and test set) \n",
    "\n",
    "\n",
    "## Today's Agenda\n",
    "\n",
    "We'll introduce pipelines through the lens of simplifying the whole classification workflow!\n",
    "\n",
    "Our data: https://www.kaggle.com/competitions/spaceship-titanic/data\n",
    "\n",
    "The goal is to classify the `Transported` column (whether or not passenger was safely transported to new planet)\n",
    "\n",
    "The competition's main metric is accuracy.\n",
    "\n",
    "#### Agenda:\n",
    "- ML Workflow without Pipeline\n",
    "- Pipeline Architecture\n",
    "- Implement Pipeline into workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import plot_confusion_matrix, recall_score, roc_auc_score,\\\n",
    "    accuracy_score, precision_score, f1_score\n",
    "from sklearn import set_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/space-titanic.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a train-test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate target and features\n",
    "X = df.drop(columns=['Transported'])\n",
    "y = df['Transported']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80/20 Train Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Workflow without Pipeline\n",
    "\n",
    "Before we dive into pipelines, let's explore the data and outline a few of the preprocessing steps we'll use later!\n",
    "\n",
    "### EDA\n",
    "\n",
    "Explore **training** data, checking both numerical and categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA Notes:\n",
    "\n",
    "What are a few important things you noticed when exploring the data?\n",
    "\n",
    "### Data Preprocessing\n",
    "\n",
    "Outline our data processing strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of numerical and categorical column names to process the data separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing ML Pipeline\n",
    "\n",
    "Let's begin exploring pipelines and how we can implement them into our workflow. We'll start by reviewing the process we went through above and discuss how we should construct our pipeline architecture.\n",
    "\n",
    "Two fundamental components:\n",
    "- Transformer(s)\n",
    "- Estimator(s)\n",
    "\n",
    "![Pipeline Architecture Diagram](./Pipeline_Architecture.png)\n",
    "\n",
    "\n",
    "The primary tool we will use is sklearn's [Pipeline object](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html). \n",
    "Since the preprocessing steps differ for numerical and categorical data, we will also utilize sklearn's [ColumnTransformer](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html) to specify the correct steps for different columns.\n",
    "\n",
    "### Create and Explore a Pipeline\n",
    "\n",
    "The first thing we should do is handle the preprocessing steps. Let's create a pipeline for preprocessing the categorical columns we didn't get to earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline to preprocess categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete Process\n",
    "\n",
    "- Pipeline to process numerical columns\n",
    "- ColumnTransformer\n",
    "- Final pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline is visualized above in a text format. You can display pipeline in a more interactive format using [set_config](https://scikit-learn.org/stable/auto_examples/miscellaneous/plot_pipeline_display.html#sphx-glr-auto-examples-miscellaneous-plot-pipeline-display-py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate\n",
    "\n",
    "Having the steps predefined and modularized makes it easy to experiment and fine-tune each part of the process!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search\n",
    "\n",
    "Using pipelines is almost exactly the same, we will just need to make a few adjustments to the parameter dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hsbc-env",
   "language": "python",
   "name": "hsbc-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
